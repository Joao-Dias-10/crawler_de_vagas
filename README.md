# ğŸ” Crawler de Vagas no LinkedIn

Este Ã© um projeto automatizado para **mineraÃ§Ã£o de dados** (web scraping) que coleta vagas de emprego publicadas no LinkedIn, utilizando a automaÃ§Ã£o do Selenium para garantir a extraÃ§Ã£o eficiente e precisa das informaÃ§Ãµes.

As vagas sÃ£o coletadas com base em uma palavra-chave (ex: "Python remoto"), processadas, limpas e armazenadas automaticamente em um banco de dados **PostgreSQL**. O sistema foi desenvolvido para ser **eficiente**, **escalÃ¡vel** e **sem duplicaÃ§Ãµes**.

## ğŸš€ Funcionalidades

- **Coleta automatizada**: O crawler utiliza o **Selenium** para navegar nas pÃ¡ginas do LinkedIn e coletar as vagas mais recentes relacionadas Ã  palavra-chave configurada.
- **Limpeza de dados**: Usando **Pandas**, o sistema trata e normaliza os dados coletados, removendo duplicatas e garantindo a qualidade das informaÃ§Ãµes.
- **Banco de dados PostgreSQL**: As vagas sÃ£o armazenadas de maneira otimizada no **PostgreSQL**, com tabelas criadas automaticamente atravÃ©s de **SQLAlchemy** e verificaÃ§Ãµes de duplicaÃ§Ã£o para manter a integridade dos dados.
- **ExecuÃ§Ã£o eficiente**: O sistema foi projetado para ser rÃ¡pido e eficaz, garantindo que apenas as vagas mais recentes e relevantes sejam coletadas, sem registros duplicados.
- **Logs de execuÃ§Ã£o**: O sistema registra logs detalhados de cada execuÃ§Ã£o, facilitando a identificaÃ§Ã£o de erros e o monitoramento do desempenho.

## ğŸ§‘â€ğŸ’» Como Executar o Projeto

### 1. **Instalar as dependÃªncias**

Primeiro, vocÃª precisa instalar as dependÃªncias necessÃ¡rias para o projeto. Certifique-se de ter o **Python 3.8 ou superior** instalado em sua mÃ¡quina. Depois, instale as dependÃªncias do projeto:

```bash
pip install -r requirements.txt
